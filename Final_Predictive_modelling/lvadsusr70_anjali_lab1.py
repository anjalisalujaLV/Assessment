# -*- coding: utf-8 -*-
"""LVADSUSR70_Anjali_Lab1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zSOI2GMqbcJhtmLN6eTxC2ANTGDpMI3K
"""

#loading dataset
import pandas as pd
df=pd.read_csv("/content/loan_approval.csv")
df.head()

#shape of the dataset
df.shape

#finding null values
df.isnull().sum()

#finding duplicate rows
df.duplicated().sum()

df.info()

df.drop(columns="loan_id",inplace=True)

df.describe()

#detecting outliers
import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(16,7))
sns.boxplot(df)
plt.show()

#detecting outlier
import numpy as np
from scipy.stats import zscore
threshold = 3.0
z_scores = zscore(df)
outliers = np.abs(z_scores) > threshold
df = df[~outliers]

df.isnull().sum()

#handling outlier
from sklearn.impute import SimpleImputer
imp = SimpleImputer(strategy="mean")
df[" residential_assets_value"]=imp.fit_transform(df[[" residential_assets_value"]])
df[" commercial_assets_value"]=imp.fit_transform(df[[" commercial_assets_value"]])
df.isnull().sum()

#encoding categorical values
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
df[" education"]=le.fit_transform(df[" education"])
df[" self_employed"]=le.fit_transform(df[" self_employed"])
df[" loan_status"]=le.fit_transform(df[" loan_status"])
df.head()

plt.figure(figsize=(15,8))
sns.heatmap(df.corr(),cmap="viridis",annot=True)

sns.pairplot(df,y_vars=" loan_status")

x=df.drop(columns=" loan_status")
y=df[" loan_status"]

# Splitting the dataset into training and test set.
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.25, random_state=0)

#feature Scaling
from sklearn.preprocessing import StandardScaler
st_x= StandardScaler()
x_train= st_x.fit_transform(x_train)
x_test= st_x.transform(x_test)

#Fitting Decision Tree classifier to the training set
from sklearn.ensemble import RandomForestClassifier
classifier= RandomForestClassifier(criterion="entropy")
classifier.fit(x_train, y_train)

#Predicting the test set result
y_pred= classifier.predict(x_test)

#Creating the metrics of the model
from sklearn.metrics import accuracy_score,confusion_matrix, classification_report
print("Accuracy Score: ",accuracy_score(y_test,y_pred))
cm= confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,5))
sns.heatmap(cm,annot=True,cmap="viridis")
plt.plot()
print("Classification Report: ")
print(classification_report(y_test,y_pred))
print("Confusion Matrix")